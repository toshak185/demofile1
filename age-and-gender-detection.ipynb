{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom pathlib import Path\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\nfrom tensorflow.keras.layers import Dropout, Input, Add, Dense, Activation, BatchNormalization, Flatten, Conv2D, MaxPooling2D, GlobalMaxPooling2D\nfrom tensorflow.keras.models import Model, load_model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = Path(\"UTKFace/\")\nfilenames = list(map(lambda x: x.name, path.glob('*.jpg')))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(filenames))\nprint(filenames[:3])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"markdown","source":"Data I have downloaded is composed of 23,708 images with age and gender in the Image Name. For Example, 1_0_0_239389.JPG image means that age is 1, gender is 0 (male) and 0 refers to the race (not needed in this task).\nSo I split the image name on ' _ ' so I can get separated age and gender with image.\nAlso, I have shuffle all the images","metadata":{}},{"cell_type":"code","source":"np.random.seed(10)\nnp.random.shuffle(filenames)\n\nage_labels, gender_labels, image_path = [], [], []\n\nfor filename in filenames:\n    image_path.append(filename)\n    temp = filename.split('_')\n    age_labels.append(temp[0])\n    gender_labels.append(temp[1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# From Unstructured data to Structured data","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame()\ndf['image'], df['age'], df['gender'] = image_path, age_labels, gender_labels","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gender_dict = {0:\"Male\",1:\"Female\"}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.astype({'age':'float32', 'gender': 'int32'})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.dtypes)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = Image.open(\"UTKFace/\"+df.image[1])\nplt.imshow(img)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(df.age)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting Images","metadata":{}},{"cell_type":"code","source":"files = df.iloc[0:20]\nplt.figure(figsize=(15,15))\nfor index, file, age, gender in files.itertuples():\n    plt.subplot(5,5, index+1)\n    img = load_img(\"UTKFace/\"+file)\n    img = np.array(img)\n    plt.imshow(img)\n    plt.title(f\"Age: {age} Gender: {gender_dict[gender]}\")\n    plt.axis('off')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since dataset is too large, It is taking a lot of time to train the model so I am splitting the data and only using half of the dataset. \nI have already shuffled all the data to ensure no biasness in the dataset.","metadata":{}},{"cell_type":"code","source":"train, test = train_test_split(df, test_size=0.85, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extracting Features","metadata":{}},{"cell_type":"code","source":"#converting Image to numpy array (extracting feature)\nx_train = []\nfor file in train.image:\n    img = load_img(\"UTKFace/\"+file, grayscale=True)\n    img = img.resize((128,128), Image.ANTIALIAS)\n    img = np.array(img)\n    x_train.append(img)\n\nx_train = np.array(x_train)\n\nx_train = x_train.reshape(len(x_train), 128,128,1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Normalizing data","metadata":{}},{"cell_type":"code","source":"x_train = x_train/255","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_gender = np.array(train.gender)\ny_age = np.array(train.age)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_size = (128,128,1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating model","metadata":{}},{"cell_type":"markdown","source":"Using Convolutional Neural Network but with skip connections. Skip connections are used in Residual NN but I have implemented CNN with little Skip connections (shortcut). ","metadata":{}},{"cell_type":"code","source":"inputs = Input((input_size))\nX = Conv2D(64, (3, 3), activation='relu', kernel_initializer = glorot_uniform(seed=0))(inputs)\nX = BatchNormalization(axis = 3)(X)\nX = MaxPooling2D((3, 3))(X)\n\nX = Conv2D(128, (3, 3), activation='relu')(X)\nX = MaxPooling2D((2, 2), strides=(2, 2))(X)\n\nX = Conv2D(256, (3, 3), activation='relu')(X)\nX = MaxPooling2D((2, 2))(X)\n\nX = Flatten()(X)\n\ndense_1 = Dense(256, activation='relu')(X)\ndense_2 = Dense(256, activation='relu' )(X)\ndense_3 = Dense(128, activation='relu' )(dense_2)\ndropout_1 = Dropout(0.4)(dense_1)\ndropout_2 = Dropout(0.4)(dense_3)\noutput_1 = Dense(1,activation='sigmoid', name='gender_output')(dropout_1)\noutput_2 = Dense(1, activation='relu', name='age_output')(dropout_2)\n\nmodel = Model(inputs=[inputs], outputs=[output_1,output_2])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=['binary_crossentropy','mae'], optimizer='adam', metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the model","metadata":{}},{"cell_type":"code","source":"model_history = model.fit(x=x_train, y=[y_gender, y_age], batch_size = 10, epochs=20, validation_split= 0.1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing loss","metadata":{}},{"cell_type":"code","source":"plt.plot(model_history.history['gender_output_loss'])\nplt.plot(model_history.history['val_gender_output_loss'])\nplt.title('Gender loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(model_history.history['age_output_loss'])\nplt.plot(model_history.history['val_age_output_loss'])\nplt.title('Age loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicting test image","metadata":{}},{"cell_type":"code","source":"index=50\nprint(\"Original: Gender = \", gender_dict[y_gender[index]],\" Age = \", y_age[index])\n\npred = model.predict(x_train[index].reshape(1, 128, 128, 1))\npred_gender = gender_dict[round(pred[0][0][0])] \npred_age = round(pred[1][0][0])\n\nprint(\"Prediction: Gender = \", pred_gender,\" Age = \", pred_age)\nplt.imshow(x_train[index].reshape(128,128), cmap='gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to the loss, the model is overfitting. I should have add some more regularization in the model to prevent overfitting but it is taking a lot of time. With 5k images, it takes 2.5 hours to fit on the train set. I stopped here but you can try adding regularization techniques to prevent overfitting.","metadata":{}},{"cell_type":"code","source":"index=20\nprint(\"Original: Gender = \", gender_dict[y_gender[index]],\" Age = \", y_age[index])\n\npred = model.predict(x_train[index].reshape(1, 128, 128, 1))\npred_gender = gender_dict[round(pred[0][0][0])] \npred_age = round(pred[1][0][0])\n\nprint(\"Prediction: Gender = \", pred_gender,\" Age = \", pred_age)\nplt.imshow(x_train[index].reshape(128,128), cmap='gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}